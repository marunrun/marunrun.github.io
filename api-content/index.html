{"posts":[{"title":"mysql中 group by排序，derived_merge优化的坑","content":"一个简单的表CREATETABLE`test`(`id`int(11)NOTNULLAUTO_INCREMENT,`spu_id`int(11)DEFAULTNULL,`price`decimal(10,2)DEFAULTNULL,PRIMARYKEY(`id`))ENGINE=InnoDBDEFAULTCHARSET=utf8mb4COLLATE=utf8mb4_unicode_ci;大概内容idspu_idprice1100200210010032004004200200对spu_id进行分组，按price从小到大排序：SELECT*FROM`test`GROUPBYspu_idORDERBYprice直接使用groupby查出来的数据是按id顺序分组的，并未达到预期尝试使用子查询，先排序再分组SELECT*FROM(SELECT*FROM`test`ORDERBYprice)AStmpGROUPBYspu_id注意：这个方式在低版本中有效。在5.7版本中引入新特性derived_merge优化过后无效了。具体无效原因我们可使用explain分析EXPLAINSELECT*FROM(SELECT*FROM`test`ORDERBYprice)AStmpGROUPBYspu_id;如图所示：MySQL将子查询优化成了一个简单查询，子查询中的排序无效~解决方法：将derived_merge关闭SEToptimizer_switch='derived_merge=off';SETGLOBALoptimizer_switch='derived_merge=off';使用特殊的查询阻止derived_merge优化可以通过在子查询中使用任何阻止合并的构造来禁用合并，尽管这些构造对实现的影响不那么明显。防止合并的构造与派生表和视图引用相同：聚合函数（SUM()，MIN()，MAX()，COUNT()，等等）DISTINCTGROUPBYHAVINGLIMITUNION要么UNIONALL选择列表中的子查询分配给用户变量仅引用文字值（在这种情况下，没有基础表）以上内容参考文档：mysql文档那么我们可以将上面的那条sql语句修改为：SELECT*FROM(SELECT*FROM`test`HAVING1=1ORDERBYprice)AStmpGROUPBYspu_id;使用having来阻止合并那么再用explain看看如有错误请指正~请多包涵","link":"https://marunrun.github.io/post/mysql-group-by-pai-xu-derived_merge-you-hua-de-keng/"},{"title":" 在 Hyperf 框架中使用 prometheus + grafana 部署基本的监控","content":"参考：hyperf利用prometheus接入服务监控,使用grafana实现数据的实时监控显示hyperf文档本文章记录本人的第一次部署所踩的坑，未深入了解prometheus和grafana如有不当的地方请指正，谢谢！一.使用docker-compose部署version:'2'networks:monitor:driver:bridgeservices:prometheus:image:prom/prometheuscontainer_name:prometheushostname:prometheusrestart:alwaysvolumes:#将你的prometheus.yml文件放在当前文件同级下，或自定义-./prometheus.yml:/etc/prometheus/prometheus.yml#-/home/prometheus/node_down.yml:/etc/prometheus/node_down.ymlports:-&quot;9090:9090&quot;networks:monitor:ipv4_address:172.18.0.3grafana:image:grafana/grafanacontainer_name:grafanahostname:grafanarestart:alwaysvolumes:#创建etc目录，data目录存储grafana的数据-./etc:/etc/grafana-./data:/var/lib/grafanaports:-&quot;3000:3000&quot;networks:monitor:ipv4_address:172.18.0.4node-exporter:image:prom/node-exportercontainer_name:node-exporterhostname:node-exporterrestart:alwaysports:-&quot;9100:9100&quot;networks:monitor:ipv4_address:172.18.0.2注意：为了避免每次docker-compose启动之后ip会发生变化，我这里配置了固定IP，请根据个人实际情况配置，或参阅docker相关文档使用命令docker-composeup启动容器二.项目配置因为对prometheus的不了解，我直接使用hyperf默认配置引入组件composerrequirehyperf/metric发布默认配置文件phpbin/hyperf.phpvendor:publishhyperf/metric在config/autoload/dependencies.php中添加对应的Redis存储return[\\Prometheus\\Storage\\Adapter::class=&gt;\\Hyperf\\Metric\\Adapter\\Prometheus\\RedisStorageFactory::class,];在上面的第一篇文章中，老哥说使用swoole_table更高效，我还不知道如何使用，有兴趣的老哥可以自己研究一下。增加中间件在config/autoload/middlewares.php文件中增加对应的中间件return['http'=&gt;[\\Hyperf\\Metric\\Middleware\\MetricMiddleware::class,],];添加metrics路由Router::get('/metrics',function(){$registry=Hyperf\\Utils\\ApplicationContext::getContainer()-&gt;get(Prometheus\\CollectorRegistry::class);$renderer=newPrometheus\\RenderTextFormat();return$renderer-&gt;render($registry-&gt;getMetricFamilySamples());});这样对项目的配置就完成了三.prometheus的配置在prometheus.yml文件中增加对应的配置scrape_configs:#Thejobnameisaddedasalabel`job=&lt;job_name&gt;`toanytimeseriesscrapedfromthisconfig.-job_name:'prometheus'#metrics_pathdefaultsto'/metrics'#schemedefaultsto'http'.static_configs:-targets:['localhost:9090']-job_name:'node'#注意这里的IP需要填写node-exporter容器的ipstatic_configs:-targets:['172.18.0.2:9100']-job_name:'skeleton'#这里填写的是宿主机的ipstatic_configs:-targets:['10.0.75.1:9502']配置完成之后，再次dokcer-composeup访问http://localhost:9090查看prometheus如图所示，node和skeleton都已启动四.Grafana配置上面都配置完了，开始配置Grafana打开http://localhost:3000默认密码是:admin/admin新建datasource左侧边栏adddatasources选择Prometheus配置datasource填写容器的IP:端口导入hyperf官方的JSON文件导入之后需要将默认的app_name改成你自己的如：admin-api就需要填写admin_api改成下划线形式查看监控在Home中你就可以看到了点进去查看到此结束，小白第一次配置监控，还有很多东西没弄清楚","link":"https://marunrun.github.io/post/hyperf-grafana/"}]}